# Application Configuration
app.name=Enterprise Streaming Analytics
app.version=1.0.0

# Kafka Configuration
kafka.bootstrap.servers=localhost:9092
kafka.consumer.group.id=streaming-analytics-group
kafka.topics.user-events=user-events
kafka.topics.notifications=notifications
kafka.topics.audit-events=audit-events
kafka.topics.security-alerts=security-alerts
kafka.topics.analytics-insights=analytics-insights
kafka.topics.real-time-analytics=real-time-analytics

# Spark Configuration
spark.master=local[*]
spark.app.name=Enterprise-Streaming-Analytics
spark.sql.streaming.checkpointLocation=/tmp/spark-checkpoint
spark.sql.warehouse.dir=/tmp/spark-warehouse
spark.streaming.batch.interval=30s
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true

# Flink Configuration
flink.parallelism=2
flink.checkpoint.interval=30000
flink.checkpoint.timeout=60000
flink.state.backend=filesystem
flink.state.checkpoints.dir=/tmp/flink-checkpoints
flink.state.savepoints.dir=/tmp/flink-savepoints

# ML Configuration
ml.model.update.interval=3600s
ml.clustering.k=5
ml.anomaly.threshold=0.8
ml.feature.window.size=5m

# Dashboard Configuration
dashboard.port=8082
dashboard.refresh.interval=5s
dashboard.alerts.max.count=50

# Security Configuration
security.alerts.enabled=true
security.suspicious.activity.threshold=50
security.failed.login.threshold=3
security.rapid.activity.window=1m

# Logging Configuration
logging.level.root=INFO
logging.level.org.apache.spark=WARN
logging.level.org.apache.flink=WARN
logging.level.org.apache.kafka=WARN
logging.level.com.enterprise.java.streaming=DEBUG

# Database Configuration (for storing analytics results)
database.url=jdbc:postgresql://localhost:5432/analytics_db
database.username=analytics_user
database.password=analytics_pass
database.pool.size=10